# -*- coding: utf-8 -*-
"""Label_3_Feature_Engineering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11zM95AohTLW-5gUpXxEfHLURt7Zrfg_2
"""

import pandas as pd
import numpy as np

#constants
L1 = 'label_1'
L2 = 'label_2'
L3 = 'label_3'
L4 = 'label_4'

LABELS = [L1, L2, L3, L4]
AGE_LABEL = L2
FEATURES = [f"feature_{i}" for i in range (1,257)]

from google.colab import drive
MOUNT_PATH='/content/drive'
drive.mount(MOUNT_PATH)

WORKING_DIR=f"{MOUNT_PATH}/MyDrive/ML/Feature_Engineering"

train = pd.read_csv(f"{WORKING_DIR}/train.csv")
train.head()

valid = pd.read_csv(f"{WORKING_DIR}/valid.csv")
valid.head()

test = pd.read_csv(f"{WORKING_DIR}/test.csv")
test.head()

"""**Scale** the dataset"""

from sklearn.preprocessing import StandardScaler

x_train = {}
y_train = {}
x_valid = {}
y_valid = {}
x_test = {}
y_test = {}

for target_label in LABELS:
  tr_df = train[train['label_2'].notna()] if target_label == 'label_2' else train
  vl_df = valid
  test_df = test

  scaler = StandardScaler()
  x_train[target_label] = pd.DataFrame(scaler.fit_transform(tr_df.drop(LABELS, axis = 1)), columns=FEATURES)
  y_train[target_label] = tr_df[target_label]

  x_valid[target_label] = pd.DataFrame(scaler.transform(vl_df.drop(LABELS, axis = 1)), columns=FEATURES)
  y_valid[target_label] = vl_df[target_label]

  x_test[target_label] = pd.DataFrame(scaler.transform(test_df.drop(LABELS, axis = 1)), columns=FEATURES)
  y_test[target_label] = test_df[target_label]

from sklearn import svm

clf = svm.SVC(kernel = 'linear')
clf.fit(x_train[L3], y_train[L3])

from sklearn import metrics

y_pred = clf.predict(x_valid[L3])
y_pred_test = clf.predict(x_test[L1])
print("Predicted labels before feature engineering", y_pred_test)

print (metrics.confusion_matrix(y_valid[L3], y_pred))
print (metrics.accuracy_score(y_valid[L3], y_pred))
print (metrics.precision_score(y_valid[L3], y_pred, average="weighted"))
print (metrics.recall_score(y_valid[L3], y_pred, average="weighted"))

"""# LinearSVC"""

# from sklearn.svm import LinearSVC
# from sklearn.feature_selection import SelectFromModel

# # Assuming L3 is an index or boolean mask for feature selection
# lsvc = LinearSVC(C=0.01, penalty="l1", dual=False, max_iter=10000).fit(x_train[L3], y_train[L3])

# model = SelectFromModel(lsvc, prefit=True)
# x_train_new = model.transform(x_train[L3])
# print(x_train_new.shape)

"""## Feature Engineering"""

from sklearn.feature_selection import SelectKBest, f_classif

selector = SelectKBest(f_classif, k=100)
X_new = selector.fit_transform(x_train[L3], y_train[L3])
print("Shape: ", X_new.shape)

clf = svm.SVC(kernel = 'linear')
clf.fit(X_new, y_train[L3])

y_pred = clf.predict(selector.transform(x_valid[L3]))
print (metrics.confusion_matrix(y_valid[L3], y_pred))
print (metrics.accuracy_score(y_valid[L3], y_pred))
print (metrics.precision_score(y_valid[L3], y_pred, average="weighted"))
print (metrics.recall_score(y_valid[L3], y_pred, average="weighted"))

"""# PCA"""

from sklearn.decomposition import PCA

pca = PCA(n_components=0.95, svd_solver='full')
pca.fit(x_train[L3])
x_train_trf = pd.DataFrame(pca.transform(x_train[L3]))
x_valid_trf = pd.DataFrame(pca.transform(x_valid[L3]))

print("Shape after PCA: ", x_train_trf.shape)

clf = svm.SVC(kernel = 'linear')
clf.fit(x_train_trf, y_train[L3])

y_pred = clf.predict(x_valid_trf)
print (metrics.confusion_matrix(y_valid[L3], y_pred))
print (metrics.accuracy_score(y_valid[L3], y_pred))
print (metrics.precision_score(y_valid[L3], y_pred, average="weighted"))
print (metrics.recall_score(y_valid[L3], y_pred, average="weighted"))

"""# SelectKBest with PCA"""

new_selector = SelectKBest(f_classif, k=50)
x_train_sb = new_selector.fit_transform(x_train[L3], y_train[L3])
x_valid_sb = new_selector.transform(x_valid[L3])
x_test_sb = new_selector.transform(x_test[L3])
print("Shape: ", x_train_sb.shape)

new_pca = PCA(n_components=0.95, svd_solver='full')
new_pca.fit(x_train_sb)
x_train_pca = pd.DataFrame(new_pca.transform(x_train_sb))
x_valid_pca = pd.DataFrame(new_pca.transform(x_valid_sb))
x_test_pca = pd.DataFrame(new_pca.transform(x_test_sb))
print("Shape after PCA: ", x_train_pca.shape)

clf = svm.SVC(kernel = 'linear')
clf.fit(x_train_pca, y_train[L3])

y_pred_sb_pca = clf.predict(x_valid_pca)
y_pred_sb_pca_test = clf.predict(x_test_pca)
print ("Predicted labels after feature engineering:", y_pred_sb_pca_test)
print (metrics.confusion_matrix(y_valid[L3], y_pred_sb_pca))
print (metrics.accuracy_score(y_valid[L3], y_pred_sb_pca))
print (metrics.precision_score(y_valid[L3], y_pred_sb_pca, average="weighted"))
print (metrics.recall_score(y_valid[L3], y_pred_sb_pca, average="weighted"))

output_df = pd.DataFrame({
    'Predicted labels before feature engineering': y_pred_test,
    'Predicted labels after feature engineering': y_pred_sb_pca_test,
    'No of new features': x_test_pca.shape[1]
})

for i in range(256):
  if i < x_test_pca.shape[1]:
    output_df[f'new_feature_{i+1}'] = x_test_pca.iloc[:, i]
  else:
    output_df[f'new_feature_{i+1}'] = None

output_df.head()

# Save the DataFrame to the specified CSV file path
output_df.to_csv(f"{WORKING_DIR}/190140L_label_3.csv", index=False)

"""### Co-relation matrix

"""

corr_matrix = x_train_pca.corr()
corr_matrix.head()

import matplotlib.pyplot as plt
import seaborn as sns

corr_treshold = 0.5
filterred_correlation_matrix = corr_matrix[(corr_matrix > corr_treshold) | (corr_matrix < -corr_treshold)]
plt.figure(figsize=(10,8))
sns.heatmap(filterred_correlation_matrix, annot=True, cmap='coolwarm', center = 0)